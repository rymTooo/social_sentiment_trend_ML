{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms.ollama import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a good assistant named Typhoon.\"),\n",
    "    (\"system\", \"Task : Your task is to perform sentiment analysis on user input.\"),\n",
    "    (\"system\", \"Format: Your answer must be in the format of {{'sentiment':[sentiment], 'confident_score':[score]}}.\"),\n",
    "    (\"system\", \"Value for [sentiment] must be a string of either 'good', 'bad', or 'neutral' only.\"),\n",
    "    (\"system\", \"Value for [score] must be a floating point between 1 and 0. confident score 1 mean the most confident and 0 mean the least confident.\"),\n",
    "    (\"user\", \"โจรวิ่งหนีตำรวจลงคลอง\"),\n",
    "    (\"assistant\", \"{{'sentiment' : 'bad', 'confident_score' : 0.95}}\"),\n",
    "    (\"user\", \"ป่าไม้ในประเทศไทย\"),\n",
    "    (\"assistant\", \"{{'sentiment' : 'neutral', 'confident_score' : '0.85'}}\"),\n",
    "    (\"user\", \"ไฟไหม้ตึกร้างบริเวณหลังโรงเรียนอนุบาล\"),\n",
    "    (\"assistant\", \"{{'sentiment' : 'bad', 'confident_score' : 0.99}}\"),\n",
    "    (\"user\", \"ประเทศไทยชนะรางวัลกีฬาแบดมินตัน\"),\n",
    "    (\"assistant\", \"{{'sentiment' : 'good', 'confident_score' : 0.95}}\"),\n",
    "    (\"user\", \"อยากติด #จุฬา ต้องมูที่ไหน✨ . แนะนำที่พระบรมราชานุสาวรีย์สองรัชกาล สถานที่ศักดิ์สิทธิ์ของชาวจุฬา เหมาะกับคนอยากติดจุฬาสุด ๆ\"),\n",
    "    (\"assistant\", \"{{'sentiment' : 'good', 'confident_score' : 0.99}}\"),\n",
    "    (\"user\", \"{user_input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(\n",
    "    base_url = \"http://192.168.123.110:11434\",\n",
    "    model=\"llama3-typhoon-8b:latest\",\n",
    "    temperature=0.1,  # Adjust temperature for diversity\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(user_input):\n",
    "    try:\n",
    "        # Generate the prompt value with context and task\n",
    "        prompt_value = template.invoke(\n",
    "            {\n",
    "                \"user_input\": user_input\n",
    "            }\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error during template invocation: {e}\")\n",
    "        prompt_value = None\n",
    "\n",
    "    if prompt_value:\n",
    "        try:\n",
    "            # Format the input and get the response from the LLM\n",
    "            formatted_input = prompt_value['content'] if isinstance(prompt_value, dict) else prompt_value\n",
    "            response = llm.invoke(formatted_input)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(f\"Error during LLM invocation: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentiment' : 'neutral', 'confident_score' : 0.85}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_input = \"หลักสูตรแพทย์อินเตอร์ 4 ปี แห่งแรกในไทย\"\n",
    "response = generate_response(user_input)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kafka_spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
